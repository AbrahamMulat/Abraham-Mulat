---
title: "SalFAU-Net: Saliency Fusion Attention U-Net for Salient  Object Detection
"
collection: publications
permalink: /publication/2024-SalFAU-Net
excerpt: 'Salient object detection (SOD) remains an important task in computer vision, with applications ranging from image segmentation to autonomous driving. Fully convolutional network (FCN)-based methods have made remarkable progress in visual saliency detection over the last few decades. However, these methods have limitations in accurately detecting salient objects, particularly in challenging scenes with multiple objects, small objects, or objects with low resolutions. To address this issue, we proposed a Saliency Fusion Attention U-Net (SalFAU-Net) model, which incorporates a saliency fusion module into each decoder block of the attention U-net model to generate saliency probability maps from each decoder block. SalFAU-Net employs an attention mechanism to selectively focus on the most informative regions of an image and suppress non-salient regions. We train SalFAU-Net on the DUTS dataset using a binary cross-entropy loss function. We conducted experiments on six popular SOD evaluation datasets to evaluate the effectiveness of the proposed method. The experimental results demonstrate that our method, SalFAU-Net, achieves competitive performance compared to other methods in terms of mean absolute error (MAE), F-measure, s-measure, and e-measure.'
date: 2024-05-10
venue: 'Arxive'
paperurl: 'https://arxiv.org/abs/2405.02906'
citation: 'Mulat, Kassaw Abraham, et al. "SalFAU-Net: Saliency Fusion Attention U-Net for Salient Object Detection." arXiv preprint arXiv:2405.02906 (2024).'
---
Salient object detection (SOD) remains an important task in computer vision, with applications ranging from image segmentation to autonomous driving. Fully convolutional network (FCN)-based methods have made remarkable progress in visual saliency detection over the last few decades. However, these methods have limitations in accurately detecting salient objects, particularly in challenging scenes with multiple objects, small objects, or objects with low resolutions. To address this issue, we proposed a Saliency Fusion Attention U-Net (SalFAU-Net) model, which incorporates a saliency fusion module into each decoder block of the attention U-net model to generate saliency probability maps from each decoder block. SalFAU-Net employs an attention mechanism to selectively focus on the most informative regions of an image and suppress non-salient regions. We train SalFAU-Net on the DUTS dataset using a binary cross-entropy loss function. We conducted experiments on six popular SOD evaluation datasets to evaluate the effectiveness of the proposed method. The experimental results demonstrate that our method, SalFAU-Net, achieves competitive performance compared to other methods in terms of mean absolute error (MAE), F-measure, s-measure, and e-measure. The code is publicly available at [this http URL](https://github.com/AbrahamMulat).

[Download paper here](https://arxiv.org/abs/2405.02906)

<!-- 
Recommended citation: Mulat, Kassaw Abraham, et al. "SalFAU-Net: Saliency Fusion Attention U-Net for Salient Object Detection." arXiv preprint arXiv:2405.02906 (2024).
-->
